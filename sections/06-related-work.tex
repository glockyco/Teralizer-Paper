\section{Related Work}
\label{sec:related-work}

Our work draws on ideas from test amplification and symbolic analysis
to automate the transformation from conventional unit tests to property-based tests.
This section reviews prior approaches to test generalization
(Section~\ref{sec:rw-generalization}),
discusses research approaches and directions that could
improve specification inference capabilities of our current prototype
(Section~\ref{sec:rw-inference})
and explores synergies with related techniques as well as developer perspectives
(Section~\ref{sec:rw-synergies}).

\subsection{Test Generalization}
\label{sec:rw-generalization}

Property-based testing~\cite{claessen_2000_quickcheck} and
parameterized unit testing~\cite{tillmann_2005_parameterized}
enable multi-input validation through general properties,
differing primarily in input generation strategy:
property-based tests (PBTs) traditionally use random generation to produce inputs,
whereas \citeauthor{tillmann_2008_pex}
suggest to execute parameterized unit tests (PUTs) symbolically,
utilizing constraint solving to select inputs
for test parameters~\cite{tillmann_2008_pex}.
Both approaches require developers
to manually specify general assertions
that hold across ranges of inputs
rather than specific input-output examples
used in conventional unit tests (CUTs).
\citeauthor{thummalapenta_2011_retrofitting}~\cite{thummalapenta_2011_retrofitting}
demonstrated manual strategies for retrofitting CUTs to PUTs.

\citeauthor{fraser_2011_generating_put}~\cite{fraser_2011_generating_put}
automated generation of PUTs from CUTs, but use tests without existing assertions
as a starting point.
This sidesteps the problem of automated oracle generalization.
However, it often causes generated PUTs to overfit the implementation~\cite{fraser_2011_generating_put}
because the lack of validated oracles 
makes it difficult to distinguish
intentional behavior from incidental state changes or outputs.
PROZE~\cite{tiwari_2024_proze} uses runtime inputs and outputs to transform CUTs to PUTs
but does not generalize beyond observed values.
JARVIS~\cite{peleg_2018_jarvis} introduced automated CUT-to-PBT transformation
using black-box analysis with predefined abstraction templates,
which produces overapproximations that require multiple related tests to constrain.
We instead use white-box symbolic analysis along concrete execution paths,
extracting path-exact specifications that generalize oracles
from individual input-output examples.

\subsection{Specification Inference}
\label{sec:rw-inference}

% Paragraph 1: Type support advances for symbolic analysis
Type support limitations fundamentally constrain
specification extraction through single-path symbolic analysis,
as discussed in Sections~\ref{sec:specification-extraction},
\ref{sec:limitations-eval-extended}, and~\ref{sec:when-it-fails}.
These limitations stem from our reliance on \ToolSPF{}~\cite{pasareanu_2013_symbolic},
a symbolic execution tool designed for path exploration.
Because full symbolic execution requires constraint solving
to determine path feasibility,
SPF only encodes constraints for types with adequate solver support.
Extending solver capabilities remains an active research area,
with recent work showing improvements for
string constraints~\cite{chen_2024_z3noodler,lotz_2025_s2s,chen_2025_ostrich2},
heap-allocated structures~\cite{copia_2022_lissa,copia_2023_pli,braione_2016_jbse},
arrays~\cite{niemetz_2023_bitwuzla},
and floating-point arithmetic~\cite{yang_2025_floating_point}.
As solver support improves and symbolic execution tools
correspondingly extend their constraint encoding,
semantics-based test generalization would also benefit.

% Paragraph 2: Alternative specification inference
Alternative approaches to specification inference
largely avoid type support limitations inherent to symbolic analysis,
but infer general specifications that describe overall method behavior
rather than path-exact constraints, which complicates oracle generalization.
Houdini~\cite{flanagan_2001_houdini} pioneered template-based inference,
generating candidate annotations and using verification to filter them.
Daikon~\cite{ernst_2007_daikon} introduced dynamic invariant detection from execution traces.
More recent tools target specific specification types:
EvoSpex~\cite{molina_2023_evospex} uses evolutionary search to infer postconditions,
SpecFuzzer~\cite{molina_2022_specfuzzer} combines grammar-based fuzzing with mutation analysis
for class specifications,
and PreCA~\cite{menguy_2022_preca} employs constraint acquisition~\cite{bessiere_2017_constraint_acquisition}
to infer preconditions from input-output observations.
LLM-based techniques offer yet another path:
SpecGen~\cite{ma_2025_specgen} uses conversational prompting
with mutation-based refinement to generate specifications from source code,
whereas ClassInvGen~\cite{sun_2025_classinvgen} co-evolves class invariants with test inputs.

\subsection{Synergies and Developer Perspective}
\label{sec:rw-synergies}

% Paragraph 1: Synergies with test generation and oracle inference
Test generalization builds on existing tests and their assertions,
creating natural synergies with techniques that produce or enrich them.
Test generation tools such as
\ToolEvoSuite{}~\cite{fraser_2011_evosuite}, Randoop~\cite{pacheco_2007_randoop},
and UTBot~\cite{utbot_2024_sbft}
produce complete unit tests through search-based, random, and hybrid approaches,
while DSpot~\cite{danglot_2019_dspot} amplifies existing tests to cover additional branches.
Oracle inference techniques such as
TOGA~\cite{dinella_2022_toga}, TOGLL~\cite{hossain_2024_togll}, and AsserT5~\cite{primbs_2025_assert5}
add assertions to tests that lack them.
All of these expand the pool of available generalization candidates.
RQ4 demonstrates this combination:
pairing \ToolEvoSuite{}'s generation with \ToolTeralizer{}'s generalization
achieves higher mutation scores at lower runtimes than test generation alone.
However, generated tests and inferred oracles
risk overfitting the implementation
rather than capturing intended specifications~\cite{barr_2015_oracle},
and this risk carries through to any subsequent generalization.

% Paragraph 2: Developer perspective and PBT barriers
For use cases beyond fully automated pipelines,
developer interaction with generalized tests becomes relevant.
Studies of test amplification show that developers filter and edit amplified tests extensively
before adding them to their test suites~\cite{wessel_2024_shaken,brandt_2022_developer}.
By making minimal structural changes
--- parameterizing inputs and expected values
while preserving the original test logic ---
test generalization may reduce friction
compared to approaches that generate entirely new test code.
However, property-based testing introduces its own complexity:
moving from example-based to property-based thinking
requires a conceptual shift that can be difficult for developers~\cite{goldstein_2024_pbt_practice,hughes_2016_experiences}.
Thus, generator constraints and generalized oracles that replace concrete values
must be presented appropriately for developers to understand and trust them.
Improving understandability of generalized tests therefore represents a research direction
that must be tackled to better support use cases
outside of fully automated testing scenarios.
