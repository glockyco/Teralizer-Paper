\newpage{}
\section{Evaluation}
\label{sec:evaluation}

Test generalization strengthens existing test suites by exploring additional inputs
within already-covered execution paths. \ToolTeralizer{} automates this transformation from
conventional unit tests to property-based tests, reducing the manual effort
traditionally required to implement such a transformation. To assess the results that
\ToolTeralizer{} achieves, we examine its benefits and limitations through four research questions:

\begin{itemize}
  \item \textbf{RQ1:} To which degree does generalization affect the mutation score of the target test suites?
  \item \textbf{RQ2:} To which degree does generalization affect the size and runtime of the target test suites?
  \item \textbf{RQ3:} What are the runtime requirements of the generalization approach?
  \item \textbf{RQ4:} What are the causes of unsuccessful generalization attempts?
\end{itemize}

These questions progress from measuring direct effects to understanding practical constraints.
RQ1 establishes effectiveness through mutation score improvements.
RQ2 quantifies associated side effects in terms of increased test suite size and execution time.
RQ3 examines the runtime costs of the approach and compares its efficiency to test generation via \ToolEvoSuite.
RQ4 analyzes failure cases to identify current limitations and guide future improvements.

Our experimental framework (Section~\ref{sec:experimental-framework}) establishes the methodology:
mutation testing measures effectiveness, three complementary datasets progressively reveal
capabilities and limitations, and nine test variants isolate different generalization effects.
Results (Sections~\ref{sec:primary-effects-eval}--\ref{sec:filtering-eval-extended})
demonstrate mutation score improvements under favorable conditions,
quantify resource trade-offs, and systematically map barriers to broader applicability.
