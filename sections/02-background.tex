\section{Background}
\label{sec:background}

This section establishes the technical foundations for semantics-based test generalization.
We first position our approach within the broader test amplification landscape,
distinguishing generalization from other enhancement strategies.
We then introduce property-based testing as our target representation,
explaining how it enables validation across entire input partitions
rather than individual test cases.
Next, we describe single-path symbolic analysis,
the key technique for extracting path-exact specifications from existing test executions.
Finally, we present mutation testing as our evaluation methodology
for measuring the effectiveness of generalized tests.

\subsection{Test Amplification}
\label{sec:test-amplification}

Test amplification exploits knowledge embedded in existing test cases (e.g.,
meaningful input data and expected outputs encoded as assertions) to
automatically enhance manually written tests with respect to specific engineering goals~\cite{danglot_2019_snowballing}.
Amplification techniques go beyond simply maximizing coverage,
targeting diverse objectives from regression detection to fault localization.
Danglot et~al.'s taxonomy \cite{danglot_2019_snowballing} distinguishes four ways in which amplification can be achieved:
AMP\textsubscript{add} creates new tests from existing ones,
AMP\textsubscript{change} generates tests targeting specific program modifications,
AMP\textsubscript{exec} varies execution conditions,
and AMP\textsubscript{mod} modifies test structure or assertions to generalize behavior.

Test generalization belongs to the AMP\textsubscript{mod} category,
transforming tests from validating individual input-output pairs
to validating properties across entire input partitions.
A test verifying that \texttt{abs(0)} returns \texttt{0}
validates this relationship for only a single value,
missing mutations that preserve behavior at that specific input but break the general property.
For instance, a mutation changing \texttt{x >= 0} to \texttt{x == 0}
still passes the original test but breaks for positive inputs (Figure~\ref{fig:regression-detection}).
Generalizing such tests requires extracting path-exact specifications
that capture program behavior across input partitions
while preserving the oracles developers have encoded in their assertions.

Central to all test amplification approaches is the oracle problem:
determining expected outputs for new test inputs~\cite{barr_2015_oracle}.
Existing tests provide validated oracles for their specific execution paths,
encoding developer knowledge about expected behavior.
Other execution paths lack such trustworthy oracles,
making it challenging to distinguish intentional from coincidental behavior.
This fundamental constraint shapes how different amplification techniques
approach the generation of new test inputs and their corresponding assertions.

\subsection{Property-Based Testing}
\label{sec:property-based-testing}

Property-based testing (PBT), pioneered by QuickCheck for Haskell~\cite{claessen_2000_quickcheck}
and now available through frameworks like ScalaCheck for Scala~\cite{nilsson_2014_scalacheck},
Hypothesis for Python~\cite{maciver_2019_hypothesis}, and \ToolJqwik{} for Java~\cite{link_2022_jqwik},
validates specifications across entire input partitions rather than individual test cases.
Where a conventional test might verify \texttt{sqrt(4)} returns \texttt{2},
a property-based test would verify that \texttt{sqrt(x) * sqrt(x) = x}
for hundreds of randomly generated non-negative values.
PBT frameworks provide three key components:
\emph{generators} that produce inputs according to specified constraints,
\emph{properties} that express invariants holding for all generated inputs,
and \emph{shrinking} algorithms that minimize failing inputs to aid debugging.
For example, the property-based test in Figure~\ref{fig:regression-detection}
uses \texttt{@Property} to indicate property-based testing,
\texttt{@Int(min=0)} to constrain input generation to non-negative integers,
and validates that \texttt{assertEquals(x, abs(x))} holds for all generated values.
The PBT framework generates many test inputs
(typically 100--1,000, with \ToolJqwik{}~\cite{link_2022_jqwik} defaulting to 1,000),
using primarily random values mixed with boundary cases.

The combination of constrained generation and property checking
enables thorough exploration of input spaces,
revealing edge cases and boundary conditions
that developers might not explicitly consider~\cite{hughes_2016_experiences,maciver_2019_hypothesis}.
However, adoption remains limited in practice~\cite{goldstein_2024_pbt_practice}.
Creating effective property-based tests requires identifying appropriate properties,
defining input generators with suitable constraints,
and translating example-based assertions into general specifications---a conceptual shift
that creates significant barriers~\cite{barr_2015_oracle,tillmann_2005_parameterized}.
Yet conventional unit tests already encode these properties implicitly:
a test verifying \texttt{abs(0) = 0} represents the property \texttt{abs(x) = x} for non-negative inputs,
but validates it for only a single point.

\subsection{Symbolic Analysis for Specification Extraction}
\label{sec:symbolic-analysis}

Automating the transformation from conventional tests to property-based specifications
requires extracting two key elements:
the \emph{path condition} that characterizes inputs following the same execution path,
and the \emph{symbolic output expression} that computes expected results for those inputs.
For the \texttt{abs(0)} test, extraction would yield
the path condition \texttt{x >= 0} and the symbolic output \texttt{x}.
These path-exact specifications enable property-based tests that validate behavior
across entire input partitions while preserving the original test's semantics.

Single-path symbolic analysis provides this capability by following
the concrete execution path of an existing test
while maintaining symbolic representations of variables~\cite{pasareanu_2013_symbolic}.
Unlike full symbolic execution, which faces path explosion when exploring all possible paths~\cite{baldoni_2018_survey,cadar_2013_symbolic},
single-path analysis records conditions only along the test's actual execution path.
This focused approach is particularly suitable for test generalization
because existing tests already identify the execution paths of interest
and provide validated oracles for those specific paths.
The analysis extracts path-exact specifications for the covered path
without the high runtime cost of exploring alternative branches.

The precision of extracted specifications depends heavily on the types of values being analyzed.
Symbolic execution tools excel at numeric constraints (e.g., \texttt{x > 0}, \texttt{y <= 2*x}),
producing exact conditions that can be directly used for input generation.
However, constraints involving strings, arrays, and complex objects remain challenging,
as symbolic representations of these types often lose precision
or become too complex for practical constraint solving~\cite{baldoni_2018_survey}.
This type limitation fundamentally shapes which tests can be successfully generalized.

\subsection{Mutation Testing for Evaluation}
\label{sec:mutation-testing}

Having established how to extract specifications from existing tests,
we need a systematic way to evaluate
whether transforming tests based on these specifications
improves test effectiveness.
Traditional coverage metrics---statement coverage~\cite{zhu_1997_software},
branch coverage~\cite{frankl_1988_applicable},
or path coverage~\cite{ntafos_1988_comparison}---cannot
distinguish between original and generalized tests
since both execute the same paths with different inputs.
Mutation testing provides the necessary discrimination by measuring a test suite's ability
to detect artificially introduced faults~\cite{jia_2011_analysis}.
The technique is grounded in two key hypotheses:
the competent programmer hypothesis (real faults are small deviations from correct programs)
and the coupling effect (tests detecting simple faults also detect complex ones)~\cite{offutt_1992_investigations}.
These hypotheses justify using small syntactic changes, i.e., mutations, as
proxies for real programming errors.

Mutation operators systematically alter program statements to create mutants,
each containing a single fault.
Common mutations operators include arithmetic replacement (\texttt{+} to \texttt{-}),
relational boundary shifts (\texttt{>} to \texttt{>=}),
logical connector changes (\texttt{\&\&} to \texttt{||}),
and constant modifications~\cite{jia_2011_analysis}.
A test suite's mutation score, i.e., the percentage of mutants it detects, provides
a quantitative measure of test effectiveness that correlates
with real fault detection capability~\cite{just_2014_mutants,papadakis_2019_mutation}.

Mutation testing reveals the limitations of single-input tests
when evaluating test amplification techniques.
The unit test verifying \texttt{abs(0) = 0}
cannot kill a mutant changing \texttt{x >= 0} to \texttt{x == 0},
since the test's single input still produces the expected output.
A generalized property-based test exploring the same execution path
with multiple inputs would detect this mutation
when positive values incorrectly return negative results.
The differential between mutants killed by original and generalized tests
quantifies the improvement in fault detection capability.
Tools like \ToolPit{}~\cite{coles_2016_pit} enable this evaluation
for Java programs.
