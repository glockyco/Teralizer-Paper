\section{Background}
\label{sec:background}

This section provides the technical foundations for semantics-based test generalization.
We first situate our work within the broader landscape of test amplification,
distinguishing generalization from other enhancement strategies.
We then introduce property-based testing as our target representation,
highlighting its ability to validate entire input partitions rather than single test cases.
Next, we describe single-path symbolic analysis,
the key technique for extracting path-exact specifications from existing test executions.
Finally, we present mutation testing as our evaluation methodology
for assessing the effectiveness of generalized tests.

\subsection{Test Amplification and Generalization}
\label{sec:test-amplification}

Test amplification exploits knowledge embedded in existing test cases (e.g.,
meaningful input data and expected outputs encoded as assertions) to
automatically enhance manually written tests to support specific engineering goals~\cite{danglot_2019_snowballing}.
Amplification techniques go beyond simply maximizing coverage,
targeting diverse objectives ranging from regression detection to fault localization.
\citeauthor{danglot_2019_snowballing}'s taxonomy~\cite{danglot_2019_snowballing} distinguishes four categories of amplification:
AMP\textsubscript{add} creates new tests from existing ones,
AMP\textsubscript{change} targets specific program modifications,
AMP\textsubscript{exec} varies execution conditions, and
AMP\textsubscript{mod} modifies test structure or assertions to generalize behavior.

Test generalization belongs to the AMP\textsubscript{mod} category,
transforming tests from validating individual input-output pairs
to validating properties across entire input partitions.
For example, a test verifying that \texttt{abs(0)} returns \texttt{0}
validates this relationship for only one input,
missing mutations that preserve behavior at that point but violate the general property.
A mutation changing \texttt{x >= 0} to \texttt{x == 0}
still passes the original test but fails for positive inputs (Figure~\ref{fig:regression-detection}).
Generalizing such tests requires extracting path-exact specifications
that capture program behavior across input partitions
while preserving the oracles developers have encoded in their assertions.

Central to all test amplification approaches is the oracle problem:
determining expected outputs for new test inputs~\cite{barr_2015_oracle}.
Existing tests provide validated oracles for their specific execution paths,
encoding developer knowledge about expected behavior.
Other execution paths lack equally trustworthy oracles,
making it difficult to distinguish intentional behavior
from incidental state changes or outputs.
This constraint fundamentally shapes how different amplification techniques
approach the generation of new test inputs and their corresponding assertions.

\subsection{Property-Based Testing as Target Representation}
\label{sec:property-based-testing}

Property-based testing (PBT), pioneered by QuickCheck for Haskell~\cite{claessen_2000_quickcheck}
and now available through frameworks like ScalaCheck for Scala~\cite{nilsson_2014_scalacheck},
Hypothesis for Python~\cite{maciver_2019_hypothesis}, and \ToolJqwik{} for Java~\cite{link_2022_jqwik},
validates specifications over entire input partitions rather than single test cases.
Where a conventional test might verify \texttt{sqrt(4)} returns \texttt{2},
a property-based test instead verifies \texttt{sqrt(x) * sqrt(x) = x}
across hundreds of randomly generated non-negative values.
PBT frameworks comprise three key components:
\emph{generators} that produce inputs according to specified constraints,
\emph{properties} that express invariants holding for all generated inputs,
and \emph{shrinking} algorithms that minimize failing inputs to simplify debugging.
For example, the property-based test in Figure~\ref{fig:regression-detection}
uses \texttt{@Property} to indicate property-based testing,
\texttt{@Int(min=0)} to constrain input generation to non-negative integers,
and validates that \texttt{assertEquals(x, abs(x))} holds for all generated values.
The PBT framework generates many test inputs
(typically 100--1,000, with \ToolJqwik{}~\cite{link_2022_jqwik} defaulting to 1,000),
using primarily random values mixed with boundary cases.

The combination of constrained generation and property checking
enables thorough exploration of input spaces,
revealing edge cases and boundary conditions
that developers might not explicitly consider~\cite{hughes_2016_experiences,maciver_2019_hypothesis}.
However, adoption remains limited in practice~\cite{goldstein_2024_pbt_practice}.
Creating effective property-based tests requires identifying appropriate properties,
defining input generators with suitable constraints,
and translating example-based assertions into general specifications: a conceptual shift
that creates significant adoption barriers~\cite{barr_2015_oracle,tillmann_2005_parameterized}.
Nevertheless, conventional unit tests already encode behavioral properties implicitly:
a test verifying \texttt{abs(0) = 0} reflects the property \texttt{abs(x) = x} for non-negative inputs,
but validates it at only a single point.

\subsection{Symbolic Analysis for Specification Extraction}
\label{sec:symbolic-analysis}

Automating the transformation from conventional tests into property-based specifications
requires extracting two elements:
the \emph{path condition} that characterizes inputs following the same execution path,
and the \emph{symbolic output expression} that computes expected results for those inputs.
For example, the \texttt{abs(0)} test yields
the path condition \texttt{x >= 0} and the symbolic output \texttt{x}.
These path-exact specifications enable property-based tests that validate behavior
across entire input partitions while preserving the original test's semantics.

Single-path symbolic analysis follows the concrete execution path of an existing test
while maintaining symbolic representations of variables~\cite{pasareanu_2013_symbolic}.
Unlike full symbolic execution, which faces path explosion
when exploring all possible paths~\cite{baldoni_2018_survey,cadar_2013_symbolic},
single-path analysis omits the backtracking and constraint solving stages
of traditional symbolic execution
and records conditions only along the executed path.
This focused approach is well suited to test generalization:
existing tests already identify the behaviors of interest
and provide validated oracles for those behaviors.
The analysis thus extracts path-exact specifications
without the computational overhead of exploring alternative branches.

The precision of extracted specifications depends heavily
on the types of values being analyzed.
Symbolic execution tools excel at numeric constraints (e.g., \texttt{x > 0}, \texttt{y <= 2*x}),
producing exact conditions that can directly guide input generation.
However, constraints involving strings, arrays, and complex objects remain challenging,
as symbolic representations of these types often lose precision
or become too complex for practical constraint solving~\cite{baldoni_2018_survey,amadini_2021_string_survey}.
These type limitations fundamentally constrain which tests can be successfully generalized.

\subsection{Mutation Testing for Evaluation}
\label{sec:mutation-testing}

Having established how to extract specifications from existing tests,
we require a systematic way to assess whether transforming tests based on these specifications
improves effectiveness.
Because original and generalized tests execute the same paths, traditional
coverage metrics cannot reveal improvements~\cite{inozemtseva_2014_coverage}.
Statement, branch, and path coverage~\cite{zhu_1997_software}
remain identical whether a test validates one input or hundreds from the same partition.
Mutation testing, in contrast, reflects the ability of a test suite to expose
behavioral differences within those paths, making it the appropriate measure for
evaluating test generalization~\cite{jia_2011_analysis}.
It rests on two hypotheses: the competent programmer hypothesis
(real faults are small deviations from correct programs) and the coupling effect
(tests that detect simple faults also detect more complex ones)~\cite{offutt_1992_investigations}.
These hypotheses support using small syntactic changes, i.e., mutations, as proxies for real programming errors.

Mutation operators systematically alter program statements
to create mutants, each containing a single fault.
Common mutation operators include arithmetic replacements (e.g., \texttt{+} to
\texttt{-}), relational boundary shifts (e.g., \texttt{>} to \texttt{>=}),
logical connector changes (e.g., \texttt{\&\&} to \texttt{||}), constant
modifications, and replacements of return values with defaults such as
\texttt{0}, \texttt{true}, or \texttt{null}~\cite{jia_2011_analysis}.
A test suite's mutation score, i.e., the proportion of mutants killed,
provides a quantitative measure of test effectiveness
that correlates with real fault detection capability~\cite{just_2014_mutants,papadakis_2019_mutation}.

Mutation testing also clarifies the limitations of single-input tests
when evaluating amplification techniques.
The unit test verifying \texttt{abs(0) = 0}
cannot kill a mutant changing \texttt{x >= 0} to \texttt{x == 0},
because the test's single input still satisfies the mutated condition.
A generalized property-based test
that exercises the same execution path with multiple inputs
will detect this mutant when positive values produce negative results.
The difference in mutants killed by the original and generalized suites
quantifies the improvement in fault detection.
Tools such as \ToolPit{}~\cite{coles_2016_pit} support this evaluation for Java programs.
