\subsection{Evaluation Setup}
\label{sec:evaluation-setup}

We systematically evaluated test generalization effectiveness, runtime cost, and practical boundaries
using nine test suite variants per project.
All experiments were run on a MacBook Air with M2 processor and 24~GB of memory,
maintaining default JVM settings (384~MB initial heap, ${1/64}$th of memory; 6~GB maximum heap, ${1/4}$th of memory).
For threats to validity resulting from this setup, see Section~\ref{sec:threats-to-validity}.
The nine project / test suite variants used / created by \ToolTeralizer{} serve the following purposes:

\begin{itemize}
  \item \VariantOriginal{}: The project before any filtering is applied by \ToolTeralizer{}.
    For \DatasetsEqBenchEs{} and \DatasetsCommonsEs{}, this project variant already contains a test suite consisting of \ToolEvoSuite{}-generated tests.
    For \DatasetCommonsDev{} and \DatasetRepoReapers{}, the test suite consists of developer-written tests.

  \item \VariantInitial{}: The project after instrumentation, test analysis, and specification extraction
    (Sections~\ref{sec:project-instrumentation}--\ref{sec:specification-extraction}),
    excluding tests unsuitable for generalization.
    This project variant is the starting point for all of the following generalizations and serves as a baseline comparison point for most evaluations.
    
  \item \VariantBaseline{}: Tests converted to property-based format while retaining only original inputs
    (Section~\ref{sec:baseline-generalization}).
    This isolates the runtime overhead of the property-based testing framework
    from actual input generalization effects.
    
  \item \VariantNaiveA{}, \VariantNaiveB{}, \VariantNaiveC{}: Basic generalization strategy
    using random input generation filtered by extracted constraints
    (Section~\ref{sec:naive-generalization}).
    The subscripts indicate 10/50/200 test executions (\ToolJqwik{} \tries{}) respectively.
    
  \item \VariantImprovedA{}, \VariantImprovedB{}, \VariantImprovedC{}: Refined generalization strategy
    incorporating constraint-aware input generation to reduce filtering failures
    (Section~\ref{sec:improved-generalization}).
    The subscripts indicate 10/50/200 test executions.
\end{itemize}

These variants enable systematic analysis across our research questions.
The progression from \VariantNaive{} to \VariantImproved{} demonstrates effectiveness trade-offs
resulting from different constraint handling strategies (RQ1).
\VariantBaseline{} quantifies the inherent runtime overhead of property-based tests compared to unit tests (RQ2).
Furthermore, the scaling behavior across 10/50/200 test executions reveals computational trade-offs
and plateau effects (RQ3).
Failure patterns across all variants highlight the current boundaries
of the proposed generalization strategies (RQ4).

Beyond the created project variant codebases, \ToolTeralizer{} captures comprehensive data and metadata
at various stages throughout its execution in a PostgreSQL database and in log files.
This data includes, for example, test and assertion descriptions,
processing task outcomes with detailed failure causes,
and complete tool outputs from JUnit, \ToolJacoco{}, and \ToolPit{}.
The full dataset, together with the \ToolTeralizer{} implementation
and data analysis notebooks, forms our replication package~\cite{replicationpackage},
supporting reproducibility and extension of our work.
