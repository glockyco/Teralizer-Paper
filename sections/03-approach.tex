\section{Approach}
\label{sec:approach}

Consider the bonus calculation method in Listing~\ref{lst:bonus-method} that returns different rates based on sales performance.
The unit test in Listing~\ref{lst:original-test} verifying \texttt{calculate(2500, 1000)} returns \texttt{250}
passes for the current implementation but would miss regressions that alter behavior within the same partition.
For instance, changing the condition from \texttt{sales/2 >= target} to \texttt{sales/2 > target}
would still pass the original test (since \texttt{2500/2 > 1000}) but breaks the boundary case.
\ToolTeralizer{} automatically transforms this into a property-based test
that explores the partition boundary, catching such regressions
that the single-input test would miss.

\begin{figure}
  \centering
  \includegraphics[width=\linewidth]{figures/fig_approach.drawio}
  \caption{Overview of Teralizer's test generalization process.}
  \Description{System architecture diagram showing Teralizer's three-phase pipeline.
  Input (left): Java Project box containing Implementation and Test Suite components.
  Center: Teralizer system with three numbered phases:
  (1) Test Analysis, (2) Specification Extraction, (3) Test Transformation.
  Below phases: Intermediate Outputs listing Processing Logs, Test/Assertion/Generalization Data,
  Input/Output Specifications, and External Tool Reports.
  Bottom row shows integrated tools: JUnit, JaCoCo, PIT, jqwik, Spoon, and JPF/SPF.
  Output (right): Generalized Tests box containing three variants: BASELINE, NAIVE, and IMPROVED.
  Thick arrows connect input to Teralizer and Teralizer to output.}
  \label{fig:approach-overview}
\end{figure}

\ToolTeralizer{} achieves this automated transformation
through a three-phase pipeline (Figure~\ref{fig:approach-overview})
that leverages existing symbolic analysis capabilities.
The complete transformation process is illustrated through
a BonusCalculator example in Listings~\ref{lst:bonus-method}--\ref{lst:java-spec-encodings}.
Our key design insight is that existing tests already encode
the necessary oracles for generalization:
developer-written assertions validate specific behaviors
that should hold for entire input partitions,
not just the single tested input.
By following the execution paths of existing tests,
we extract path-exact specifications only for behaviors that developers
have explicitly validated, avoiding the risk of overfitting
to implementation details of untested paths.
The three main phases of \ToolTeralizer{}'s pipeline are:

\begin{itemize}
    \item \textbf{Test Analysis} (Section~\ref{sec:test-analysis}) --
    identifies executable test methods via JUnit reports,
    and detects assertions as well as corresponding methods under test via static analysis.
    \item \textbf{Specification Extraction} (Section~\ref{sec:specification-extraction}) --
    uses \ToolSPFLong{} (\ToolSPF{}) in constraint collection mode
    for single-path symbolic analysis to infer input/output specifications
    of the methods under test along the execution paths exercised by identified tests.
    \item \textbf{Test Transformation} (Section~\ref{sec:test-transformation}) --
    uses the extracted input/output specifications
    to create property-based \ToolJqwik{} tests from original JUnit tests,
    generating three variants (\VariantBaseline{}, \VariantNaive{}, and \VariantImproved{})
    to systematically study the mutation detection effectiveness and runtime efficiency
    of different input generation strategies.
\end{itemize}

Throughout the pipeline, we apply filtering to focus on tests
amenable to semantics-based generalization (detailed analysis in Section~\ref{sec:limitations-eval}).
Current limitations reflect both implementation scope and fundamental challenges:
we require pure functions with numeric parameters,
clear assertion-method relationships identifiable through \ToolTeralizer{}'s static analysis,
and developer-provided assertions that serve as validated oracles.
Extracting complete constraints for strings, arrays, and objects remains
an open research challenge -- \ToolSPF{} and other symbolic analysis tools
provide only limited support for these types~\cite{baldoni_2018_survey}.
Even with complete constraints, efficiently generating satisfying inputs
for property-based testing remains computationally expensive,
as filtering-based approaches suffer from poor efficiency with complex constraints~\cite{claessen_2000_quickcheck,link_2022_jqwik}.
These limitations define the scope within which we demonstrate
the feasibility of semantics-based generalization.

Our implementation targets Java 5--8 projects (limited by \ToolSPF{})
with Maven or Gradle build systems and JUnit 4/5 test suites.
To systematically understand the impact of these limitations,
we capture comprehensive metrics throughout the transformation pipeline,
documenting not only successful generalizations
but also the specific reasons tests cannot be generalized.
This data, available in our replication package~\cite{replicationpackage},
provides the research community with insights into
what makes tests amenable to generalization
and which technical advances would enable broader applicability.

Before processing begins, 
\ToolTeralizer{} prepares the target project by detecting the build system (Maven or Gradle)
and injecting necessary dependencies including \ToolJqwik{}, \ToolPit{}, and \ToolJacoco{}.
This instrumentation creates modified build files while preserving originals,
enabling the pipeline to execute tests and collect mutation testing results
required for evaluating generalization effectiveness.

\subsection{Test Analysis}
\label{sec:test-analysis}

The test analysis phase identifies generalizable tests
by establishing clear mappings between test assertions and the methods they validate.
This assertion-method mapping is challenging: tests often invoke multiple methods
and use intermediate variables,
requiring data flow analysis to determine which method an assertion actually tests.
For instance, our BonusCalculator test (Listing~\ref{lst:original-test}) contains multiple calculate invocations
stored in separate variables, followed by multiple assertions on those variables.
Our analysis must trace backwards from each assertion to identify
which specific calculate call produced the asserted value.
This precise mapping is essential because all input generators
must first include the original concrete input values
to guarantee we never miss inputs that developers explicitly encoded in their tests,
with additional inputs generated afterwards (Section~\ref{sec:three-variant-design}).
Section~\ref{sec:limitations-eval} analyzes how often this mapping fails in practice.

\ToolTeralizer{} first executes the original test suite
and parses JUnit XML reports to identify successfully executed test methods.
Using JUnit reports rather than custom static analysis
avoids reimplementing JUnit's test handling logic
for ignored tests and test failures,
ensuring we only process tests that actually pass
and can serve as reliable oracles for generalization.
For each identified test,
we use static analysis based on Spoon~\cite{pawlak_2016_spoon}
to locate assertions (calls to methods in \texttt{org.\-junit.\-Assert}
or \texttt{org.\-junit.\-jupiter.\-api.\-Assertions})
and trace data flow backwards to identify which method call
produced the value being asserted.
We currently support four assertion types:
\texttt{assertEquals}, \texttt{assertTrue}, \texttt{assertFalse}, and \texttt{assertThrows}.

Test analysis produces assertion-method pairs that identify
which specific method invocation each assertion validates,
along with the concrete input values used in the original test.
This information enables the specification extraction phase
to obtain precise path conditions and symbolic outputs for each tested behavior.

Our data flow analysis handles different assertion types systematically.
For \texttt{assertThrows} assertions, 
we extract the executable body from the lambda expression
and identify the last method call,
which typically represents the operation expected to throw the exception.
For value assertions (\texttt{assertEquals}, \texttt{assertTrue}, \texttt{assertFalse}),
we locate the actual parameter (whose position varies between JUnit versions)
and trace its origin.
If the actual value comes from a direct method invocation,
we use that method immediately.
If it comes from a variable,
we trace back to the variable's assignment statement
and extract the method call from the right-hand side.
When this analysis cannot resolve a clear method invocation,
we return null to indicate that the assertion
cannot be mapped to a testable method.

Our current implementation requires that tested methods
are pure functions: deterministic, side-effect-free,
and dependent only on their input parameters.
This constraint reflects both \ToolSPF{}'s symbolic execution capabilities
and our deliberate scope decisions --
\ToolSPF{} produces accurate constraints for numeric computations
but cannot model complex state changes or external effects,
while our single-path approach requires deterministic behavior
to ensure generalized tests validate the same semantics as originals.
Additionally, we only support numeric parameters
(\texttt{byte}, \texttt{short}, \texttt{int}, \texttt{long}, \texttt{float}, \texttt{double})
where \ToolSPF{} produces accurate constraints.
Section~\ref{sec:limitations-eval} analyzes how often
these constraints limit applicability in practice,
while Section~\ref{sec:limitations} discusses the fundamental challenges
in extending type support beyond current capabilities.

\subsection{Specification Extraction}
\label{sec:specification-extraction}

Having identified assertion-method pairs through test analysis,
the specification extraction phase uses \ToolSPF{}
to extract input/output specifications for each assertion.
These specifications capture two key elements:
the path condition that characterizes which inputs
follow the same execution path as the test,
and the symbolic output expression that computes
the expected result for any input in that partition.
Examples of extracted specifications from the \texttt{BonusCalculator.calculate} method are shown
in Listing~\ref{lst:input-output-specs}.
These specifications enable the test transformation phase
(Section~\ref{sec:test-transformation})
to create input generators and generalized oracles
for property-based tests.

We leverage \ToolSPF{}'s constraint collection mode,
which tracks symbolic state along concrete test paths
without performing constraint solving for path exploration.
This mode follows the test's execution path while maintaining
symbolic representations of variables,
collecting path conditions at each branch point.
We modified \ToolSPF{} to consistently bypass constraint solving
during collection mode, as the original implementation
occasionally invoked the solver despite the collection-only setting.
Section~\ref{sec:runtime-eval} evaluates the runtime efficiency
of this approach.

To enable \ToolSPF{} analysis of individual assertions,
we generate driver programs that isolate each assertion-method pair
for focused symbolic analysis.
The driver program recreates the test execution context
by instantiating the test class,
executing setup methods (\texttt{@Before}, \texttt{@BeforeClass}, etc.),
and invoking the target test method with only the specific assertion of interest.
This isolation ensures that symbolic analysis focuses precisely on the tested method
without interference from unrelated test logic or assertions.

During execution, a custom \ToolSPF{} listener monitors method entry and exit events
to extract specifications when the tested method completes.
The listener captures both concrete execution results
(actual parameter values and return values)
and symbolic results (path conditions and symbolic output expressions).
Execution limits prevent resource exhaustion and downstream failures:
60-second timeout (empirically sufficient for most methods),
100,000-character path condition limit (prevents both memory issues
and Java's 64KB method bytecode limit in generated tests),
and 100-step depth limit (avoids infinite recursion).
Once specifications are extracted and serialized,
\ToolSPF{} terminates immediately since only the single test path requires analysis.

\subsection{Test Transformation}
\label{sec:test-transformation}

With specifications extracted for each assertion-method pair,
the test transformation phase converts JUnit tests into property-based \ToolJqwik{} tests.
We use \ToolJqwik{}\footnote{\url{https://github.com/jqwik-team/jqwik}}
as property-based testing framework
because it is actively maintained, well-documented, and integrates seamlessly with JUnit 5,
unlike alternatives such as junit-quickcheck\footnote{\url{https://github.com/pholser/junit-quickcheck}}
and quicktheories\footnote{\url{https://github.com/quicktheories/QuickTheories}}.

\subsubsection{Transformation Pipeline}
\label{sec:transformation-pipeline}

For each assertion-method pair, we generate a new test class containing
a property-based test (as shown in Listing~\ref{lst:generalized-test}).
The transformation process:
(1) clones the original test class,
(2) removes all test methods except the target,
(3) removes all assertions except the target,
(4) replaces \texttt{@Test} with \texttt{@Property} annotations,
(5) adds a \texttt{TestParameters} class to encapsulate all numeric parameters
(a simple data structure with public fields for each generalizable parameter),
(6) adds a \texttt{TestParametersSupplier} to generate inputs,
and (7) replaces method arguments with values from \texttt{TestParameters}.
We generate one class per assertion rather than combining multiple assertions
because PIT mutation testing operates at class-level granularity --
this isolation ensures that failed generalizations do not prevent
successful ones from being included in mutation testing.
The original test method is preserved alongside the generalized version
to maintain backward compatibility.

\subsubsection{Three-Variant Ablation Design}
\label{sec:three-variant-design}

We generate three variants following standard ablation study methodology
to isolate different aspects of the approach,
enabling systematic analysis of how constraint complexity affects generation effectiveness
(Section~\ref{sec:key-findings}).
The implementation differences between these variants are illustrated
in Listings~\ref{lst:baseline-supplier}--\ref{lst:improved-supplier}:
%
\textbf{\VariantBaseline{}} uses only the original test inputs,
measuring pure framework overhead without additional input generation.
This variant creates a \texttt{TestParametersSupplier} that returns
a single \texttt{TestParameters} instance with the original values.
%
\textbf{\VariantNaive{}} first includes the original test inputs,
then generates additional random inputs matching parameter types
and filters them against the input specification.
This approach generates additional values independently for each parameter,
then applies a filter function encoding the complete path condition.
For complex constraints, this leads to high rejection rates
and \texttt{TooManyFilterMissesException}s when generation cannot find valid inputs.
%
\textbf{\VariantImproved{}} first includes the original test inputs,
then generates additional inputs by partially encoding constraints
during input generation
to reduce filtering failures.
This variant analyzes the input specification to extract
equality and inequality constraints,
then generates additional values respecting these constraints
before applying the complete filter.
The next section details this constraint encoding strategy.

\subsubsection{Constraint Encoding Strategy}
\label{sec:constraint-encoding}

The \VariantImproved{} variant analyzes input specifications
to identify constraints that can be directly encoded in \ToolJqwik{} arbitraries.
We support five types of simple constraints:
equality (\texttt{x == y}),
strict inequality (\texttt{x < y}, \texttt{x > y}),
and non-strict inequality (\texttt{x <= y}, \texttt{x >= y}),
where \texttt{x} and \texttt{y} can be variables or constants.
Complex expressions involving arithmetic operations
(e.g., \texttt{x + y == z}) or function calls
(e.g., \texttt{sin(x) > 0}) cannot be encoded
and must be handled through filtering.
%
To handle circular dependencies (e.g., \texttt{a >= b \&\& b >= a}),
we rewrite constraints to apply only to the variable with the highest index.
For example, \texttt{a >= b} becomes \texttt{b <= a},
allowing us to first generate \texttt{a} without constraints,
then generate \texttt{b} respecting both \texttt{b <= a} and \texttt{b >= a}
(which together imply \texttt{b == a}).
This constraint rewriting enables us to generate custom jqwik arbitraries
that respect variable dependencies during runtime input generation.
Algorithm~\ref{alg:constraint-encoding} describes this constraint-aware generation process systematically.
We handle only simple equality and inequality constraints
to keep the approach tractable.
More complex constraints are addressed through filtering rather than encoding.
%
Despite these optimizations, some valid constraints lead to unsatisfiable
situations during generation.
For example, with \texttt{b > a \&\& b <= 0},
if we generate \texttt{a = 0}, no valid \texttt{b} exists.
In such cases, we return an empty arbitrary,
prompting \ToolJqwik{} to retry with different values.

\begin{algorithm}[t]
\caption{Constraint-Aware Input Generation (\VariantImproved{})}
\label{alg:constraint-encoding}
\begin{algorithmic}[1]
\REQUIRE Input specification $S$, Parameters $P = \{p_1, \ldots, p_n\}$
\ENSURE Generated test inputs satisfying $S$
\STATE Assign indices: $idx(p_i) = i$ for $i \in \{1, \ldots, n\}$
\FORALL{constraints $c \in S$ of form $p_i \odot p_j$ where $\odot \in \{=, <, \leq, >, \geq\}$}
    \IF{$idx(p_i) > idx(p_j)$}
        \STATE Add constraint to $p_i$ based on $p_j$
    \ENDIF
    \IF{$idx(p_j) > idx(p_i)$}
        \STATE Rewrite constraint and add to $p_j$ based on $p_i$
        \STATE E.g., $p_i < p_j$ becomes $p_j > p_i$
    \ENDIF
\ENDFOR
\FOR{each parameter $p_i$ in index order}
    \STATE $E_i \gets$ equality constraints for $p_i$
    \STATE $L_i \gets$ lower bound constraints for $p_i$  
    \STATE $U_i \gets$ upper bound constraints for $p_i$
    \IF{$E_i \neq \emptyset$}
        \STATE Generate $p_i = $ value from first equality constraint
    \ELSIF{$L_i \neq \emptyset$ or $U_i \neq \emptyset$}
        \STATE $lower \gets \max(L_i)$ if exists, else type minimum
        \STATE $upper \gets \min(U_i)$ if exists, else type maximum
        \STATE Generate $p_i \in [lower, upper]$
    \ELSE
        \STATE Generate $p_i$ randomly within type bounds
    \ENDIF
\ENDFOR
\STATE Apply filter for non-encodable constraints
\STATE \RETURN generated inputs if filter passes
\end{algorithmic}
\end{algorithm}

{
\begin{genericfloat}[tbph]
\newpage{}
\noindent
\begin{minipage}[t]{0.48\textwidth}

\begin{lstlisting}[language=Java, caption={Implementation of the \texttt{calculate} method.}, label=lst:bonus-method]
class BonusCalculator {
  int calculate(int sales, int target) {
    if (sales / 2 >= target) {
      // exceptional performance
      return sales / 10; 
    } else if (sales >= target) {
      // good performance
      return sales / 20; 
    }
    // bad performance
    return 0; 
  }
}
\end{lstlisting}

\begin{lstlisting}[language=Java, caption={Original test for the \texttt{calculate} method.}, label=lst:original-test]
@Test
void testCalculate() {
  BonusCalculator c = new BonusCalculator();
  int b1 = c.calculate(2500, 1000);
  int b2 = c.calculate(1500, 1000);
  int b3 = c.calculate(500, 1000);
  assertEquals(250, b1);
  assertEquals(75, b2);
  assertEquals(0, b3);
}
\end{lstlisting}

\begin{lstlisting}[caption={Input/output specifications of \texttt{calculate}.}, label=lst:input-output-specs]
exceptional performance:
- input:  sales / 2 >= target
- output: sales / 10 
good performance:
- input:  sales / 2 < target && sales >= target
- output: sales / 20
bad performance:
- input:  sales / 2 < target && sales < target
- output: 0
\end{lstlisting}

\begin{lstlisting}[language=Java, caption={Generalized test for the \textit{good performance} assertion.}, label=lst:generalized-test]
@Property(supplier = ..., tries = ...)
void testCalculate(TestParams _p_) {
  BonusCalculator c = new BonusCalculator();
  ...
  int b2 = c.calculate(_p_.sales, _p_.target);
  ...
  assertEquals(calculateExpected(_p_), b2);
}
\end{lstlisting}

\end{minipage}
\hfill
\begin{minipage}[t]{0.48\textwidth}

\begin{lstlisting}[language=Java, caption={\VariantBaseline{} supplier for \texttt{testCalculate(...)} inputs. The supplier uses the same inputs as the original test.}, label=lst:baseline-supplier]
class BaselineSupplier {
  Arbitrary get() {
    return Arbitraries.just(
      new TestParams(1500, 1000));
  }
}
\end{lstlisting}

\begin{lstlisting}[language=Java, caption={\VariantNaive{} supplier for \texttt{testCalculate(...)} inputs. The supplier generates random inputs and then filters them to only test cases that match the input specification.}, label=lst:naive-supplier]
class NaiveSupplier {
  Arbitrary get() {
    return Arbitraries.integers().flatMap(
      sales -> Arbitraries.integers().map(
        target -> new TestParams(sales, target)))
    .filter(this::satisfiesInputSpec);
  }
}
\end{lstlisting}

\begin{lstlisting}[language=Java, caption={\VariantImproved{} supplier for \texttt{testCalculate(...)} inputs. The supplier (partially) encodes the input specification, thus reducing \texttt{TooManyFilterMissesExceptions} compared to \VariantNaive{}.}, label=lst:improved-supplier]
class ImprovedSupplier {
  Arbitrary get() {
    return Arbitraries.integers().flatMap(
      target -> Arbitraries.integers()
        // sales >= target is encoded
        // sales / 2 < target is not encoded
        .between(target, Integer.MAX_VALUE)
        .map(sales -> 
          new TestParams(sales, target)))
    .filter(this::satisfiesInputSpec);
  }
}
\end{lstlisting}

\begin{lstlisting}[language=Java, caption={Java encodings of input/oputput specifications.}, label=lst:java-spec-encodings]
boolean satisfiesInputSpec(TestParams _p_) {
  return _p_.sales / 2 <= _p_.target
    && _p_.sales >= _p_.target;
}

int calculateExpected(TestParams _p_) {
  return _p_.sales / 20;
}
\end{lstlisting}
\end{minipage}
\end{genericfloat}
}

\subsection{Filtering Strategy}
\label{sec:all-filtering}

Automated test generalization succeeds only when tests meet specific structural and semantic requirements.
\ToolTeralizer{} applies systematic filtering across three levels
that correspond to the pipeline phases,
characterizing the boundaries of current generalization capabilities.
The three-level cascade identifies distinct categories of constraints:
test-level structural prerequisites,
assertion-level specification extraction requirements,
and generalization-level property generation feasibility.
Section~\ref{sec:limitations-eval} provides detailed empirical analysis of filtering outcomes,
quantifying exclusion rates and their implications for broader applicability.

\subsubsection{Test-Level Filtering}

Test-level filtering excludes tests that cannot provide reliable foundations for generalization.
The \textbf{NonPassingTest} filter excludes tests that fail during execution,
including originally failing tests and tests that fail after disabling \ToolEvoSuite{}'s isolation features
(required to prevent \ToolPit{} crashes during property-based test execution).
The \textbf{TestType} filter restricts processing to standard \texttt{@Test} annotations;
parameterized tests (\texttt{@ParameterizedTest}) and other specialized test types
would require different transformation strategies not implemented in \ToolTeralizer{}.
The \textbf{NoAssertions} filter excludes tests lacking explicit assertions in the main test method body,
including tests that validate behavior solely through successful execution
and tests that delegate assertion logic to helper methods.
\ToolTeralizer{}'s intraprocedural static analysis cannot trace assertions in helper methods;
interprocedural analysis could address this implementation limitation.

\subsubsection{Assertion-Level Filtering}

Assertion-level filtering identifies which assertions \ToolTeralizer{} can successfully process
given its static analysis capabilities and \ToolSPF{}'s constraint generation limitations.
The \textbf{MissingValue} filter excludes assertions where \ToolTeralizer{}'s data flow analysis
cannot identify the tested method,
commonly due to conditional assignments across branches,
indirect method calls through variables,
or unresolved method declarations in inheritance hierarchies.
The \textbf{ParameterType} filter restricts generalization to methods with numeric and boolean parameters
(\texttt{byte}, \texttt{short}, \texttt{int}, \texttt{long}, \texttt{float}, \texttt{double}, \texttt{boolean}).
While \ToolSPF{} can track symbolic values for strings, arrays, and objects,
extracting complete constraints for these types remains limited~\cite{baldoni_2018_survey},
and the partial constraints \ToolSPF{} provides cannot be readily encoded as \ToolJqwik{} input generators.
The \textbf{AssertionType} filter supports \texttt{assertEquals}, \texttt{assertTrue}, \texttt{assertFalse}, and \texttt{assertThrows};
unsupported assertions like \texttt{assertSame}, \texttt{assertNull}, and \texttt{assertArrayEquals}
involve object identity or structural comparisons
that \ToolTeralizer{}'s specification extraction approach cannot handle.
Additional exclusions result from \ToolSPF{} execution failures:
missing native method models,
exceeded analysis limits (60-second timeout, 100,000-character path condition limit),
and null pointer exceptions in \ToolTeralizer{}'s specification extraction implementation.

\subsubsection{Generalization-Level Filtering}

Generalization-level filtering validates that extracted specifications produce executable property-based tests.
The primary failure mode is \texttt{TooManyFilterMissesException}s
when \ToolJqwik{} cannot generate inputs satisfying path constraints within retry limits
(typically when discard ratio exceeds 0.5).
This reflects the fundamental inefficiency of filtering-based input generation
for complex constraints~\cite{claessen_2000_quickcheck,link_2022_jqwik}.
\VariantImproved{} reduces these failures by encoding simple equality and inequality constraints
during input generation (Section~\ref{sec:constraint-encoding}),
but complex constraints involving arithmetic expressions must still be handled through filtering.
Additional failures stem from inaccurate specifications
when \ToolTeralizer{} encounters patterns it cannot properly model:
implicit preconditions, assertions within loops, or tested methods called within loops.
These filtering outcomes identify specific areas where enhanced static analysis,
extended type support, and more sophisticated constraint handling
could expand \ToolTeralizer{}'s generalization capabilities.
